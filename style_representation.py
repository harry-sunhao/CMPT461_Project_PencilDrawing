# -*- coding: utf-8 -*-
"""Style_Representation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/harry-sunhao/CMPT461_Project_PencilDrawing/blob/main/Style_Representation.ipynb
"""

from google.colab import drive
from google.colab import files
import tensorflow as tf
from IPython.display import display, Image
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import copy
import glob
import os
import tarfile

"""# Prepare
Weight File: https://drive.google.com/file/d/1LVFw1erzVS4yjsBjFBRbVM8uQnczMAj3/view?usp=sharing

1. Download this file
2. Upload this file in your workspace.
Notice: the weight default name is vgg16_norm_weights.h5
"""

weight_path = "vgg16_norm_weights.h5"
if os.path.exists(weight_path) == False:
  print("No Weight File")

"""# Data
* Visualize the data
* Pre-process the data
"""

style_path = tf.keras.utils.get_file(
    "style1.jpg",
    "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ32-WNDVjfbgveDNK23BANN81oMzpowBXkaA&usqp=CAU")
print('Style Path: {}'.format(style_path))

"""## Utils for the images
1. load_image - a function that loads image from the paths
2. imshow - a fuction to plot the image, when given a tensor
3. imsave - a fuction to save the image from a tensor
"""

def load_img(path_to_img):
  '''
  This function helps load the image from the path
  inputs:
    path_to_img = The path of the image
  outputs:
    the image itself in form of tf.tensor
  '''
  # Open the file, reads content as string
  img = tf.io.read_file(path_to_img)
  # Decode image, (0 to 1)
  img = tf.image.decode_image(img, channels=3, dtype=tf.float32)
  # Resizing image
  img = tf.image.resize(img, (224,224))
  # Expand dimension for the model (batch, h,w,c)
  img = tf.expand_dims(img,0)
  return img

def imshow(image, title=None):
  '''
  This function helps in visualizing the image
  inputs:
    image - Tensor
    title - The title of the plot
  '''
  if len(image.shape) > 3:
    image = tf.squeeze(image, axis=0)

  plt.imshow(image)
  if title:
    plt.title(title)

def imsave(image, name):
  '''
  This function helps in saving the image
  inputs:
    image - Tensor
    name - The name of the image
  '''
  if len(image.shape) > 3:
    image = tf.squeeze(image, axis=0)
  fig = plt.figure(figsize=(5,5))
  plt.imshow(image)
  plt.axis('off')
  plt.savefig(name)
  plt.close()

style_image = load_img(style_path)
imshow(style_image, 'Style Image')

"""# Models
We will use the `VGG16` model.

And also make intermediate models for our convenience.
"""

vgg = tf.keras.applications.VGG16(include_top=False, weights=None)
vgg.load_weights(weight_path)
vgg.trainable = False

LAYERS =  [
    'block1_conv1',
    'block2_conv1',
    'block3_conv1',
    'block4_conv1',
    'block5_conv1']

vgg_models = list()
for layer_name in LAYERS:
  layer_output = vgg.get_layer(layer_name).output
  vgg_models.append(
      tf.keras.models.Model(inputs=vgg.input,outputs=layer_output)
  )

"""# Style Representations"""

def gram_matrix(input_tensor):
  '''
  inputs:
    inputs_tensor - Input Tensor
  outputs:
    Gram matrix of the tensor
  '''
  result = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)
  return result

def compute_layer_style_cost(act_Style, act_Gen):
  '''
  inputs:
  act_Style - activation Style
  act_Gen - activation Generate
  outputs:
  The gram loss
  '''
  m, n_h, n_w, n_c = act_Gen.get_shape().as_list()

  GS = gram_matrix(act_Style)
  GG = gram_matrix(act_Gen)

  J_style_layer = tf.reduce_sum(tf.square(GS-GG))/((2 * n_c * n_w * n_h)**2)
  return J_style_layer

@tf.function()
def compute_style_cost(vgg_models, STYLE_LAYERS, style_image, generated_image):
  '''
  inputs:
    vgg_model - Intermediate VGG MODEL
    STYLE_LAYERS - The style layer
    gen_image - the generated image
  '''

  J_style = 0
  for idx, (layer_name, coeff) in enumerate(STYLE_LAYERS):
    pre_G = generated_image*255.0
    pre_G = tf.keras.applications.vgg19.preprocess_input(pre_G)
    act_G = vgg_models[idx](pre_G)

    pre_S = style_image*255.0
    pre_S = tf.keras.applications.vgg19.preprocess_input(pre_S)
    act_S = vgg_models[idx](pre_S)

    J_style_layer = compute_layer_style_cost(act_S, act_G)

    J_style += coeff * J_style_layer

  return J_style

STYLE_LAYERS = [
    ['block1_conv1', 0.2],
    ['block2_conv1', 0.2],
    ['block3_conv1', 0.2],
    ['block4_conv1', 0.2],
    ['block5_conv1', 0.2]]

# Test for output
white_noise = np.random.normal(size = (1,224,224,3), loc = 0.5, scale = 0.1)

compute_style_cost(vgg_models, STYLE_LAYERS, style_image, white_noise)

def train_step(vgg_models, STYLE_LAYERS, style_image, white_noise, loss_hist):
  with tf.GradientTape() as tape:
    style_loss = compute_style_cost(vgg_models, STYLE_LAYERS, style_image, white_noise)

  l = style_loss.numpy()
  loss_hist.append(l)
  grad = tape.gradient(style_loss,white_noise)
  opt.apply_gradients([(grad, white_noise)])
  white_noise.assign(tf.clip_by_value(white_noise, clip_value_min=0.0, clip_value_max=1.0))

"""## Iterations"""

STYLE_LAYERS = [
    ['block1_conv1', 0],
    ['block2_conv1', 0],
    ['block3_conv1', 0],
    ['block4_conv1', 0],
    ['block5_conv1', 0]]

! mkdir layer0 layer1 layer2 layer3 layer4

# Test for loss and images
gen_images = list()
losses = list()
for idx in range(5):
  STYLE_LAYERS_temp = copy.deepcopy(STYLE_LAYERS)
  STYLE_LAYERS_temp[idx][1] = 1.0
  s = tf.constant(style_image)
  w = tf.Variable(np.random.normal(size = (1,224,224,3), loc = 0.5, scale = 0.1))
  opt = tf.keras.optimizers.Adam()
  loss_hist = list()
  for i in tqdm(range(10000)):
    if i%50 == 0:
      imsave(w,'layer{}/style{}.png'.format(idx,i))
    train_step(vgg_models, STYLE_LAYERS_temp, s, w, loss_hist)
  gen_images.append(w)
  losses.append(loss_hist)

plt.figure(figsize=(25,5))
for idx, loss_hist in enumerate(losses):
  plt.subplot(1,5,idx+1)
  plt.plot(loss_hist)
  plt.title('Block{}'.format(idx+1))

plt.figure(figsize=(25,5))
for idx, gen_image in enumerate(gen_images):
  plt.subplot(1,5,idx+1)
  imshow(gen_image, 'Block{}'.format(idx+1))

show_gif('layer4.gif')

"""## Aggregate"""

STYLE_LAYERS = [
    ['block1_conv1', 0.2],
    ['block2_conv1', 0.2],
    ['block3_conv1', 0.2],
    ['block4_conv1', 0.2],
    ['block5_conv1', 0.2]]

! mkdir aggregate

# Test for loss and images
s = tf.constant(style_image)
w = tf.Variable(np.random.normal(size = (1,224,224,3), loc = 0.5, scale = 0.1))
opt = tf.keras.optimizers.Adam()
loss_hist = list()
for i in tqdm(range(10000)):
  if i%50 == 0:
      imsave(w,'aggregate/style{}.png'.format(i))
  train_step(vgg_models, STYLE_LAYERS, s, w, loss_hist)

plt.plot(loss_hist)
plt.title('All Blocks Aggregated')

imshow(w, 'All Blocks Aggregated')

"""## Export the Data"""

def make_targz_one_by_one(tar, source_dir):
  
  for root,dir_name,files_list in os.walk(source_dir):
    for file in files_list:
      pathfile = os.path.join(root, file)
      tar.add(pathfile)


dir_list = ['layer0','layer1','layer2','layer3','layer4','layer5','aggregate']
output_filename = "compress.tar"
tar = tarfile.open(output_filename,"w")
for dir in dir_list:
  print('/content/'+dir)
  make_targz_one_by_one(tar, '/content/'+dir)

tar.close()
files.download(output_filename)